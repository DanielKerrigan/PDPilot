{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDPilot Bike Rentals Example\n",
    "\n",
    "This notebook demonstrates how to use PDPilot to anlayze a model trained on the [hourly bike rentals dataset](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset), with pre-processing by [Christoph Molnar](https://christophm.github.io/interpretable-ml-book/bike-data.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import pandas to load the data, our chosen model class from scikit-learn, and the `partial_dependence` function and `PDPilotWidget` class from PDPilot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pdpilot import partial_dependence, PDPilotWidget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've hosted a pre-processed version of the dataset as a gist. Here, we load it into a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://gist.githubusercontent.com/DanielKerrigan/f324b392dc9a58d8bd8f8d79e1101a12/raw/c3b4760c9facfac26bcab2cd7465c4cab88ef304/bike-hour.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(dataset_url).drop(columns=[\"yr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is \"cnt\", which is the count of the number of bikes rented during that hour.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather situation (\"weathersit\") feature is categorical, so we'll one-hot encode it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_hot = pd.get_dummies(df_original, columns=[\"weathersit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_one_hot.drop(columns=[\"cnt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_original[\"cnt\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train a random forest model on the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=20)\n",
    "regr.fit(df_X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will give PDPilot a list of features that we want it to compute plots for. Here, we get a list of the names of all of the features. Note that we use the original names of one-hot encoded features. For example, this list includes \"weathersit\" instead of \"weathersit_1\", \"weathersit_2\", etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df_original.columns if col != \"cnt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one-hot encoded features, we need to tell PDPilot which columns belong to which feature and what values those columns correspond to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_features = {\n",
    "    \"weathersit\": [\n",
    "        (\"weathersit_1\", \"clear\"),\n",
    "        (\"weathersit_2\", \"mist\"),\n",
    "        (\"weathersit_3\", \"rain\"),\n",
    "        (\"weathersit_4\", \"storm\"),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ordinal encoded features, we can optionally supply string names for the feature values to use rather than the integer values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_value_mappings = {\n",
    "    \"season\": {1: \"winter\", 2: \"spring\", 3: \"summer\", 4: \"fall\"},\n",
    "    \"weekday\": {0: \"S\", 1: \"M\", 2: \"T\", 3: \"W\", 4: \"R\", 5: \"F\", 6: \"S\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDPilot can support up to a few thousand instances. Here we randomly sample 1000 instances from our dataset and get the corresponding ground truth labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df_X.sample(1000, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = y[subset.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass this data to the `partial_dependence` function to compute the necessary data for the widget. For regression, the function that we pass to the `predict` parameter is expected to take a pandas dataframe containing instances as input and return a 1D numpy array containing the predictions for those instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = partial_dependence(\n",
    "    predict=regr.predict,\n",
    "    df=subset,\n",
    "    features=features,\n",
    "    one_hot_features=one_hot_features,\n",
    "    feature_value_mappings=feature_value_mappings,\n",
    "    resolution=20,\n",
    "    seed=34,\n",
    "    n_jobs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run the widget.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = PDPilotWidget(\n",
    "    predict=regr.predict, df=subset, labels=labels, pd_data=pd_data, seed=56, height=650\n",
    ")\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
