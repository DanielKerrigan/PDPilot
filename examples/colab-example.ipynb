{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDPilot Bike Rentals Colab Example\n",
    "\n",
    "This notebook demonstrates how to use PDPilot to anlayze a model trained on the [hourly bike rentals dataset](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset), with pre-processing by [Christoph Molnar](https://christophm.github.io/interpretable-ml-book/bike-data.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we install PDPilot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdpilot -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import pandas to load the data, our chosen model class from scikit-learn, and the `partial_dependence` function and `PDPilotWidget` class from PDPilot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pdpilot import partial_dependence, PDPilotWidget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have some additional imports to make custom Jupyter widgets work in Colab notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've hosted a pre-processed version of the dataset as a gist. Here, we load it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'https://gist.githubusercontent.com/DanielKerrigan/f324b392dc9a58d8bd8f8d79e1101a12/raw/c3b4760c9facfac26bcab2cd7465c4cab88ef304/bike-hour.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(dataset_url).drop(columns=['yr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is \"cnt\", which is the count of the number of bikes rented during that hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather situation (\"weathersit\") feature is categorical, so we'll one-hot encode it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_hot = pd.get_dummies(df_original, columns=['weathersit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_one_hot.drop(columns=['cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_original['cnt'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train a random forest model on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=20)\n",
    "regr.fit(df_X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will give PDPilot a list of features that we want it to compute plots for. Here, we get a list of the names of all of the features. Note that we use the original names of one-hot encoded features. For example, this list includes \"weathersit\" instead of \"weathersit_1\", \"weathersit_2\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df_original.columns if col != 'cnt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one-hot encoded features, we need to tell PDPilot which columns belong to which feature and what values those columns correspond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_features = {\n",
    "    'weathersit': [\n",
    "        ('weathersit_1', 'clear'),\n",
    "        ('weathersit_2', 'mist'),\n",
    "        ('weathersit_3', 'rain'),\n",
    "        ('weathersit_4', 'storm')\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ordinal encoded features, we can optionally supply string names for the feature values to use rather than the integer values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_value_mappings = {\n",
    "    'season': {\n",
    "        1: 'winter',\n",
    "        2: 'spring',\n",
    "        3: 'summer',\n",
    "        4: 'fall'\n",
    "    },\n",
    "    'weekday': {\n",
    "        0: 'S',\n",
    "        1: 'M',\n",
    "        2: 'T',\n",
    "        3: 'W',\n",
    "        4: 'R',\n",
    "        5: 'F',\n",
    "        6: 'S'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDPilot can support up to a few thousand instances. Here we randomly sample 500 instances from our dataset and get the corresponding ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df_X.sample(500)\n",
    "labels = y[subset.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass this data to the `partial_dependence` function to compute the necessary data for the widget. For regression, the function that we pass to the `predict` parameter is expected to take a pandas dataframe containing instances as input and return a 1D numpy array containing the predictions for those instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = partial_dependence(\n",
    "    predict=regr.predict,\n",
    "    df=subset,\n",
    "    features=features,\n",
    "    one_hot_features=one_hot_features,\n",
    "    feature_value_mappings=feature_value_mappings,\n",
    "    resolution=20,\n",
    "    n_jobs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run the widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w = PDPilotWidget(\n",
    "    predict=regr.predict,\n",
    "    df=subset,\n",
    "    labels=labels,\n",
    "    pd_data=pd_data,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
