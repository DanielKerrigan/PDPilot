{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from itertools import combinations\n",
    "\n",
    "import pdpexplorer\n",
    "from pdpexplorer.pdp import partial_dependence\n",
    "\n",
    "from imodels import GreedyRuleListClassifier, SlipperClassifier, BoostedRulesClassifier, OneRClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bike-sharing.csv').drop(columns=['yr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['label', 'prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (df['label'] >= df['label'].median()).to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [col for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = GreedyRuleListClassifier(max_depth=5)\n",
    "# m.fit(X.drop(columns=['hr']), y=y, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.rules_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m._print_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pred(df):\n",
    "#     y = []\n",
    "    \n",
    "#     for index, row in df.iterrows():\n",
    "#         if row[\"hr\"] >= 7.0:\n",
    "#             y.append(1)\n",
    "#         elif row[\"hum\"] >= 0.58:\n",
    "#             y.append(0)\n",
    "#         else:\n",
    "#             y.append(0)\n",
    "        \n",
    "#     return np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.all(pred(df) == m.predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['hr'] >= 7.0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['hr'] < 7.0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df['hr'] < 7.0) & (df['hum'] < 0.58)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = SlipperClassifier()\n",
    "# m.fit(X, y=y, feature_names=features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = BoostedRulesClassifier()\n",
    "# m.fit(X, y=y, feature_names=features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = OneRClassifier()\n",
    "# m.fit(X, y=y, feature_names=list(features));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.plot_tree(clf, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_cluster(X, y, feature_names):\n",
    "    # This code is adapted from \n",
    "    # https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html\n",
    "    clf = DecisionTreeClassifier(max_depth=3, ccp_alpha=0.01)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    children_left = clf.tree_.children_left\n",
    "    children_right = clf.tree_.children_right\n",
    "    threshold = clf.tree_.threshold\n",
    "    feature = clf.tree_.feature\n",
    "    value = clf.tree_.value\n",
    "    label = np.argmax(clf.tree_.value, axis=2).ravel()\n",
    "\n",
    "    stack = [(0, [])]\n",
    "\n",
    "    rules = []\n",
    "\n",
    "    while len(stack) > 0:\n",
    "        node_id, path = stack.pop()\n",
    "        is_split_node = children_left[node_id] != children_right[node_id]\n",
    "\n",
    "        if is_split_node:\n",
    "            left_condition = {\n",
    "                'feature': feature_names[feature[node_id]],\n",
    "                'sign': '<=',\n",
    "                'threshold': threshold[node_id]\n",
    "            }\n",
    "            stack.append((children_left[node_id], path + [left_condition]))\n",
    "\n",
    "            right_condition = {\n",
    "                'feature': feature_names[feature[node_id]],\n",
    "                'sign': '>',\n",
    "                'threshold': threshold[node_id]\n",
    "            }\n",
    "            stack.append((children_right[node_id], path + [right_condition]))\n",
    "            \n",
    "        elif label[node_id] == 1:\n",
    "            num_instances = value[node_id].sum()\n",
    "            num_correct = value[node_id][0,1]\n",
    "\n",
    "            rule = {\n",
    "                'conditions': path,\n",
    "                'num_instances': num_instances,\n",
    "                'num_correct': num_correct,\n",
    "                'accuracy': num_correct / num_instances,\n",
    "            }\n",
    "\n",
    "            rules.append(rule)\n",
    "            \n",
    "    return rules\n",
    "        \n",
    "print(describe_cluster(X, y, feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
